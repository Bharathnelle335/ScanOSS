name: ScanCode Toolkit Scan with tags input

on:
  workflow_dispatch:
    inputs:
      scan_type:
        description: "Scan type"
        required: true
        type: choice
        options:
          - repo
          - zip
          - docker
        default: repo

      docker_image:
        description: "Docker image (if scan_type=docker)"
        required: false
        default: "alpine:latest"   # you can type anything when running workflow

      repo_url:
        description: "Repo URL (if scan_type=repo)"
        default: "https://github.com/psf/requests.git"

      git_ref:
        description: "Branch / tag / commit to scan (leave blank if included in repo_url via /tree/<ref> or /releases/tag/<tag>)"
        required: false
        default: ""

      archive_file:
        description: "Archive file (if scan_type=zip)"
        default: "sample.zip"

      enable_license_scan:
        type: boolean
        description: "Run license + license-text detection"
        default: true
      enable_copyright_scan:
        type: boolean
        description: "Run copyright + author + email detection"
        default: true
      enable_metadata_scan:
        type: boolean
        description: "Run metadata scans (urls + file info)"
        default: false
      enable_package:
        type: boolean
        description: "Detect packages and manifests"
        default: true
      enable_sbom_export:
        type: boolean
        description: "Export SPDX and CycloneDX SBOM"
        default: false

jobs:
  scancode:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout workflow repo
        uses: actions/checkout@v4

      - name: Install dependencies
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y git unzip jq python3 python3-pip
          pip3 install --no-input pandas openpyxl

      - name: Prepare input
        shell: bash
        run: |
          set -euo pipefail
          SCAN_TYPE="${{ github.event.inputs.scan_type }}"
          REPO_URL_RAW="${{ github.event.inputs.repo_url }}"
          GIT_REF_RAW="${{ github.event.inputs.git_ref }}"
          ARCHIVE_FILE="${{ github.event.inputs.archive_file }}"
          DOCKER_IMAGE="${{ github.event.inputs.docker_image }}"

          case "$SCAN_TYPE" in
            repo)
              if [[ -z "${REPO_URL_RAW}" ]]; then
                echo "âŒ repo_url is required for scan_type=repo" >&2
                exit 1
              fi

              # Normalize GitHub web URLs & extract ref if present
              BASE_URL=""
              DET_REF=""
              case "$REPO_URL_RAW" in
                https://github.com/*/tree/*)
                  DET_REF="${REPO_URL_RAW##*/tree/}"
                  BASE_URL="${REPO_URL_RAW%%/tree/*}.git"
                  ;;
                https://github.com/*/commit/*)
                  DET_REF="${REPO_URL_RAW##*/commit/}"
                  BASE_URL="${REPO_URL_RAW%%/commit/*}.git"
                  ;;
                https://github.com/*/releases/tag/*)
                  DET_REF="${REPO_URL_RAW##*/releases/tag/}"
                  BASE_URL="${REPO_URL_RAW%%/releases/tag/*}.git"
                  ;;
                https://github.com/*/*)
                  BASE_URL="${REPO_URL_RAW%.git}.git"
                  ;;
                *)
                  BASE_URL="${REPO_URL_RAW}"
                  ;;
              esac

              # Strip refs/* prefixes if pasted and decide final ref
              GIT_REF="${GIT_REF_RAW#refs/heads/}"
              GIT_REF="${GIT_REF#refs/tags/}"
              if [[ -z "${GIT_REF}" ]]; then
                if [[ -n "${DET_REF}" ]]; then
                  GIT_REF="${DET_REF}"
                else
                  GIT_REF="main"
                fi
              fi

              echo "ðŸ”§ Repo URL (normalized): ${BASE_URL}"
              echo "ðŸ”§ Ref: ${GIT_REF}"
              rm -rf input_repo

              echo "ðŸ”Ž Checking if '${GIT_REF}' is a branch/tag..."
              if git ls-remote --tags --heads "${BASE_URL}" | grep -qE "refs/(heads|tags)/${GIT_REF}$"; then
                echo "âœ… Found branch/tag. Shallow cloningâ€¦"
                git clone --depth 1 --branch "${GIT_REF}" "${BASE_URL}" input_repo || true
              fi

              if [[ ! -d input_repo ]]; then
                echo "â„¹ï¸  Not a branch/tag (or shallow clone failed). Full clone + checkoutâ€¦"
                git clone "${BASE_URL}" input_repo
                cd input_repo
                git fetch --all --tags --prune
                if ! git checkout --detach "${GIT_REF}"; then
                  echo "âŒ Ref '${GIT_REF}' not found in ${BASE_URL}" >&2
                  echo "   Tip: use a branch (e.g., main), a tag (e.g., v1.2.3), or a commit SHA."
                  exit 1
                fi
                cd -
              fi
              INPUT_PATH="input_repo"
              LABEL="$(basename "${BASE_URL%.*}")"
              ;;

            zip)
              unzip -q "$ARCHIVE_FILE" -d input_zip
              INPUT_PATH="input_zip"
              base="$(basename "$ARCHIVE_FILE")"; LABEL="${base%.*}"
              ;;

            docker)
              docker pull "$DOCKER_IMAGE"
              docker save "$DOCKER_IMAGE" -o docker-image.tar
              INPUT_PATH="docker-image.tar"
              LABEL="$(echo "$DOCKER_IMAGE" | tr '/:' '__')"
              ;;

            *)
              echo "âŒ Unknown scan_type: $SCAN_TYPE"
              exit 1
              ;;
          esac

          echo "INPUT_PATH=$INPUT_PATH" >> "$GITHUB_ENV"
          echo "SCAN_LABEL=$LABEL" >> "$GITHUB_ENV"

      - name: Download ScanCode Toolkit
        shell: bash
        run: |
          set -euo pipefail
          git clone --depth 1 https://github.com/aboutcode-org/scancode-toolkit.git
          cd scancode-toolkit
          ./scancode --version

      - name: Run ScanCode Toolkit (JSON/SBOM) + dedicated Copyrights CSV
        shell: bash
        run: |
          set -euo pipefail
          cd scancode-toolkit

          SCANCODE_OPTS=""
          if [ "${{ github.event.inputs.enable_license_scan }}" = "true" ]; then
            SCANCODE_OPTS="$SCANCODE_OPTS --license --license-text"
          fi
          if [ "${{ github.event.inputs.enable_metadata_scan }}" = "true" ]; then
            SCANCODE_OPTS="$SCANCODE_OPTS --url --info"
          fi
          if [ "${{ github.event.inputs.enable_package }}" = "true" ]; then
            SCANCODE_OPTS="$SCANCODE_OPTS --package"
          fi
          # copyright/email controlled separately for JSON and CSV below

          OUT_PREFIX="$GITHUB_WORKSPACE/scancode_${SCAN_LABEL}"
          IN_PATH="$GITHUB_WORKSPACE/$INPUT_PATH"

          # Main JSON (include copyright/email if enabled)
          MAIN_JSON_OPTS="$SCANCODE_OPTS"
          if [ "${{ github.event.inputs.enable_copyright_scan }}" = "true" ]; then
            MAIN_JSON_OPTS="$MAIN_JSON_OPTS --copyright --email"
          fi

          ./scancode $MAIN_JSON_OPTS --json-pp "${OUT_PREFIX}.json" "$IN_PATH"

          if [ "${{ github.event.inputs.enable_sbom_export }}" = "true" ]; then
            ./scancode --spdx-tv   "${OUT_PREFIX}.spdx.tv"   "$IN_PATH"
            ./scancode --spdx-rdf  "${OUT_PREFIX}.spdx.rdf"  "$IN_PATH"
            ./scancode --cyclonedx-json "${OUT_PREFIX}.cdx.json" "$IN_PATH"
          fi

          # Dedicated CSV: copyrights only (clean separate file)
          if [ "${{ github.event.inputs.enable_copyright_scan }}" = "true" ]; then
            ./scancode -c --csv "${OUT_PREFIX}_copyrights.csv" "$IN_PATH"
          fi

          echo "OUT_PREFIX=$OUT_PREFIX" >> "$GITHUB_ENV"

      - name: Convert JSON â†’ Excel
        shell: bash
        run: |
          set -euo pipefail
          python3 - <<'EOF'
          import pandas as pd, json, glob, os

          lic_rows, file_rows, copy_rows, dep_rows = [], [], [], []

          # find our single JSON (prefix is scancode_<label>.json)
          for jf in glob.glob("scancode_*.json"):
              with open(jf, "r", encoding="utf-8") as f:
                  try:
                      data = json.load(f)
                  except Exception:
                      continue

              # --- license detections (from top-level license_detections) ---
              for lic in data.get("license_detections", []):
                  for ref in lic.get("reference_matches", []):
                      lic_rows.append({
                          "file_path": ref.get("from_file"),
                          "license_expression": lic.get("license_expression"),
                          "license_expression_spdx": lic.get("license_expression_spdx"),
                          "start_line": ref.get("start_line"),
                          "end_line": ref.get("end_line"),
                          "score": ref.get("score"),
                          "rule_url": ref.get("rule_url"),
                          "matched_text": (ref.get("matched_text") or "")[:200],
                      })

              # --- files block (dynamic details per file) ---
              for fi in data.get("files", []):
                  file_rows.append({
                      "path": fi.get("path"),
                      "type": fi.get("type"),
                      "licenses": "; ".join([l.get("spdx_license_key","") for l in fi.get("licenses", []) if l.get("spdx_license_key")]),
                      "copyrights": "; ".join([c.get("value","") for c in fi.get("copyrights", []) if c.get("value")]),
                      "authors": "; ".join([a.get("value","") for a in fi.get("authors", []) if a.get("value")]),
                      "emails": "; ".join([e.get("value","") for e in fi.get("emails", []) if e.get("value")]),
                      "urls": "; ".join([u.get("value","") for u in fi.get("urls", []) if u.get("value")]),
                  })

                  # flattened rows for a separate Copyrights_Detail sheet
                  for c in fi.get("copyrights", []):
                      val = c.get("value")
                      if val:
                        copy_rows.append({"file": fi.get("path"), "copyright": val})
                  for a in fi.get("authors", []):
                      val = a.get("value")
                      if val:
                        copy_rows.append({"file": fi.get("path"), "author": val})
                  for e in fi.get("emails", []):
                      val = e.get("value")
                      if val:
                        copy_rows.append({"file": fi.get("path"), "email": val})

              # --- dependencies (top-level) ---
              for dep in data.get("dependencies", []):
                  dep_rows.append({
                      "purl": dep.get("purl"),
                      "requirement": dep.get("extracted_requirement"),
                      "scope": dep.get("scope"),
                      "is_runtime": dep.get("is_runtime"),
                      "is_optional": dep.get("is_optional"),
                      "is_direct": dep.get("is_direct"),
                      "datafile": dep.get("datafile_path"),
                  })

          df_lic   = pd.DataFrame(lic_rows)
          df_files = pd.DataFrame(file_rows)
          df_copy  = pd.DataFrame(copy_rows)
          df_deps  = pd.DataFrame(dep_rows)

          # Optional Summary sheet
          summary_blocks = []
          if not df_lic.empty:
              lic_summary = df_lic.groupby("license_expression_spdx", dropna=True)["file_path"].count().reset_index()
              lic_summary.rename(columns={"file_path":"count"}, inplace=True)
              lic_summary.insert(0,"Category","Licenses")
              summary_blocks.append(lic_summary)

          if not df_copy.empty:
              df_copy_summary = df_copy.copy()
              df_copy_summary.insert(0,"Category","Copyrights/Authors/Emails")
              summary_blocks.append(df_copy_summary)

          if not df_deps.empty:
              dep_summary = df_deps[["purl","requirement","scope"]].copy()
              dep_summary.insert(0,"Category","Dependencies")
              summary_blocks.append(dep_summary)

          df_summary = pd.concat(summary_blocks, ignore_index=True) if summary_blocks else pd.DataFrame()

          scan_label = os.getenv("SCAN_LABEL", "scancode")
          out_xlsx = f"scancode_{scan_label}.xlsx"

          with pd.ExcelWriter(out_xlsx) as w:
              if not df_lic.empty:   df_lic.to_excel(w, "Licenses_Detail",   index=False)
              if not df_files.empty: df_files.to_excel(w, "Files_Detail",     index=False)
              if not df_copy.empty:  df_copy.to_excel(w, "Copyrights_Detail", index=False)
              if not df_deps.empty:  df_deps.to_excel(w, "Dependencies",      index=False)
              if not df_summary.empty: df_summary.to_excel(w, "Summary",      index=False)

          print(f"âœ… Wrote Excel: {out_xlsx}")
          EOF

      - name: Upload ScanCode reports
        uses: actions/upload-artifact@v4
        with:
          name: scancode-reports-${{ env.SCAN_LABEL }}
          path: |
            scancode_${{ env.SCAN_LABEL }}.json
            scancode_${{ env.SCAN_LABEL }}.xlsx
            scancode_${{ env.SCAN_LABEL }}.spdx.tv
            scancode_${{ env.SCAN_LABEL }}.spdx.rdf
            scancode_${{ env.SCAN_LABEL }}.cdx.json
            scancode_${{ env.SCAN_LABEL }}_copyrights.csv
          # retention-days: 30  # uncomment if you want shorter retention

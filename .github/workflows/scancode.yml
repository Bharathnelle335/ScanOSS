name: OSS Compliance - SCANOSS only (Docker, Git or Uploaded Source) with tags

# Helpful run title in Actions UI (includes optional client tag)
run-name: >-
  SCANOSS ${{ github.event.inputs.scan_type }} â€¢
  ${{ github.event.inputs.docker_image || github.event.inputs.git_url || github.event.inputs.archive_url || 'upload' }} â€¢
  ${{ github.event.inputs.client_run_id }}

on:
  workflow_dispatch:
    inputs:
      scan_type:
        description: 'Scan a Docker image, Git repo, uploaded source.zip or image.tar archive'
        required: true
        default: 'docker'
        type: choice
        options: [docker, git, upload-zip, upload-tar]

      docker_image:
        description: 'Docker image name (e.g., nginx:latest) [scan_type: docker]'
        required: false

      git_url:
        description: 'Git repository URL (e.g., https://github.com/user/repo OR https://github.com/user/repo/tree/v1.2.3)'
        required: false

      git_ref:
        description: 'Branch / tag / commit to scan [scan_type: git]. Leave blank if included in git_url (tree/commit/tag).'
        required: false
        default: ''

      enable_scanoss:
        description: 'Run SCANOSS OSS scan?'
        required: false
        default: 'true'
        type: boolean

      # NEW: remote archive URL support for upload-zip/upload-tar
      archive_url:
        description: 'Remote .zip or .tar(.gz|.xz) URL (used only when scan_type is upload-zip or upload-tar)'
        required: false
        default: ''

      # Optional opaque tag from your UI so you can find this run/artifact later
      client_run_id:
        description: 'Opaque run tag from the UI (for status + artifact lookup)'
        required: false
        default: ''

jobs:
  oss-compliance:
    runs-on: ubuntu-latest
    env:
      # Picked up automatically by scanoss-py if present (donâ€™t hardcode secrets)
      SCANOSS_API_KEY: ${{ secrets.SCANOSS_API_KEY }}
      # Optional tenant endpoint; safe to leave unset
      SCANOSS_API_URL: ${{ secrets.SCANOSS_API_URL }}

    steps:
      # ----------------------------------------------------
      # Checkout & tooling
      # ----------------------------------------------------
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install system deps
        run: |
          sudo apt-get update
          sudo apt-get install -y git curl unzip xz-utils

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install SCANOSS and Excel deps
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install --user scanoss pandas openpyxl
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"
          export PATH="$HOME/.local/bin:$PATH"

      # ----------------------------------------------------
      # Prepare source
      # ----------------------------------------------------
      - name: Pull Docker image
        if: ${{ github.event.inputs.scan_type == 'docker' }}
        run: docker pull "${{ github.event.inputs.docker_image }}"

      - name: Clone Git repository
        if: ${{ github.event.inputs.scan_type == 'git' }}
        shell: bash
        run: |
          set -euo pipefail
          RAW_URL="${{ github.event.inputs.git_url }}"
          RAW_REF="${{ github.event.inputs.git_ref }}"

          if [[ -z "${RAW_URL}" ]]; then
            echo "âŒ git_url is required when scan_type=git" >&2
            exit 1
          fi

          # Normalize URL and extract ref if user pasted a web URL
          BASE_URL=""
          DET_REF=""

          case "$RAW_URL" in
            https://github.com/*/tree/*)
              DET_REF="${RAW_URL##*/tree/}"; DET_REF="${DET_REF%%/*}"
              BASE_URL="${RAW_URL%%/tree/*}.git"
              ;;
            https://github.com/*/commit/*)
              DET_REF="${RAW_URL##*/commit/}"; DET_REF="${DET_REF%%/*}"
              BASE_URL="${RAW_URL%%/commit/*}.git"
              ;;
            https://github.com/*/releases/tag/*)
              DET_REF="${RAW_URL##*/releases/tag/}"; DET_REF="${DET_REF%%/*}"
              BASE_URL="${RAW_URL%%/releases/tag/*}.git"
              ;;
            https://github.com/*/*)
              BASE_URL="${RAW_URL%.git}.git"
              ;;
            *)
              BASE_URL="${RAW_URL}"
              ;;
          esac

          # Clean up refs/heads|refs/tags if pasted
          GIT_REF="${RAW_REF#refs/heads/}"
          GIT_REF="${GIT_REF#refs/tags/}"

          # Choose ref: explicit > detected > main
          if [[ -z "${GIT_REF}" ]]; then
            if [[ -n "${DET_REF}" ]]; then
              GIT_REF="${DET_REF}"
            else
              GIT_REF="main"
            fi
          fi

          echo "ðŸ”§ Repo: ${BASE_URL}"
          echo "ðŸ”§ Ref:  ${GIT_REF}"

          rm -rf repo-to-scan

          echo "ðŸ”Ž Checking if '${GIT_REF}' is a branch/tag..."
          if git ls-remote --tags --heads "${BASE_URL}" | grep -qE "refs/(heads|tags)/${GIT_REF}$"; then
            echo "âœ… Branch/tag found. Shallow cloning..."
            git clone --depth 1 --branch "${GIT_REF}" "${BASE_URL}" repo-to-scan || true
          fi

          if [[ ! -d repo-to-scan ]]; then
            echo "â„¹ï¸  Not a branch/tag (or shallow clone failed). Full clone + checkout..."
            git clone "${BASE_URL}" repo-to-scan
            cd repo-to-scan
            git fetch --all --tags --prune
            if ! git checkout --detach "${GIT_REF}"; then
              echo "âŒ Ref '${GIT_REF}' not found in ${BASE_URL}" >&2
              echo "   Tip: use a branch (e.g., main), a tag (e.g., v1.2.3), or a commit SHA."
              exit 1
            fi
            cd -
          fi

          echo "âœ” Checked out commit: $(cd repo-to-scan && git rev-parse HEAD)"

      - name: Unzip uploaded source archive (or download ZIP)
        if: ${{ github.event.inputs.scan_type == 'upload-zip' }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p uploaded-source
          URL="${{ github.event.inputs.archive_url }}"
          if [[ -n "$URL" ]]; then
            echo "ðŸ“¥ Downloading ZIP from $URL â€¦"
            curl -L --fail --retry 3 --retry-delay 2 "$URL" -o input.zip
            unzip -q input.zip -d uploaded-source
          else
            unzip -q input/*.zip -d uploaded-source
          fi

      - name: Extract uploaded TAR archive (or download TAR)
        if: ${{ github.event.inputs.scan_type == 'upload-tar' }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p uploaded-tar
          URL="${{ github.event.inputs.archive_url }}"
          if [[ -n "$URL" ]]; then
            echo "ðŸ“¥ Downloading TAR from $URL â€¦"
            curl -L --fail --retry 3 --retry-delay 2 "$URL" -o input.tar
            SRC="input.tar"
          else
            SRC=$(ls input/*.tar 2>/dev/null | head -n1 || true)
            if [[ -z "$SRC" ]]; then
              echo "âŒ No TAR file found in input/ and no archive_url provided." >&2
              exit 1
            fi
          fi
          # Handle .tar.gz/.tgz, .tar.xz/.txz, and plain .tar
          NAME="${SRC##*/}"
          case "$NAME" in
            *.tar.gz|*.tgz)  tar -xzf "$SRC" -C uploaded-tar ;;
            *.tar.xz|*.txz)  tar -xJf "$SRC" -C uploaded-tar ;;
            *.tar)           tar -xf  "$SRC" -C uploaded-tar ;;
            *)               echo "â„¹ï¸ Unknown TAR extension; trying generic -xf"; tar -xf "$SRC" -C uploaded-tar ;;
          esac

      # ----------------------------------------------------
      # Auto-detect Dockerfile & optional image build
      # (skip if scan_type == docker because the image already exists)
      # ----------------------------------------------------
      - name: Detect Dockerfile and optionally build image
        id: autodock
        if: ${{ github.event.inputs.scan_type != 'docker' }}
        run: |
          set -e
          # Resolve scan directory
          SCAN_DIR="."
          if [[ "${{ github.event.inputs.scan_type }}" == "git"        ]]; then SCAN_DIR="repo-to-scan"; fi
          if [[ "${{ github.event.inputs.scan_type }}" == "upload-zip" ]]; then SCAN_DIR="uploaded-source"; fi
          if [[ "${{ github.event.inputs.scan_type }}" == "upload-tar" ]]; then SCAN_DIR="uploaded-tar"; fi

          HAS_IMAGE=false
          IMAGE_REF=""

          # Locate first Dockerfile (any depth)
          DF_PATH=$(find "$SCAN_DIR" -type f -iname 'Dockerfile' | head -n 1 || true)

          if [[ -n "$DF_PATH" ]]; then
            echo "Dockerfile found at $DF_PATH â€“ attempting image build"
            # Try to build; if it fails, we continue the workflow gracefully
            if docker build -t auto-scanned-image:latest "$(dirname "$DF_PATH")"; then
              HAS_IMAGE=true
              IMAGE_REF="auto-scanned-image:latest"
              echo "âœ… Docker image built successfully"
            else
              echo "âš ï¸  Docker build failed â€“ skipping image-based scan"
            fi
          else
            echo "No Dockerfile found â€“ skipping image build"
          fi

          # Pass state to later steps
          echo "has_image=$HAS_IMAGE"  >> "$GITHUB_OUTPUT"
          echo "image_ref=$IMAGE_REF"  >> "$GITHUB_OUTPUT"

      # ----------------------------------------------------
      # Compute label + run tag (sanitized), for artifact names
      # ----------------------------------------------------
      - name: Set LABEL and RUN_TAG env
        shell: bash
        run: |
          set -euo pipefail
          RUN_TAG_IN="${{ github.event.inputs.client_run_id }}"
          if [ -z "${RUN_TAG_IN}" ]; then RUN_TAG_IN="${GITHUB_RUN_ID}"; fi

          MODE="${{ github.event.inputs.scan_type }}"
          RAW=""
          if [[ "$MODE" == "docker" ]]; then
            RAW="${{ github.event.inputs.docker_image }}"
          elif [[ "$MODE" == "git" ]]; then
            RAW="${{ github.event.inputs.git_url }}"
          elif [[ "$MODE" == "upload-zip" || "$MODE" == "upload-tar" ]]; then
            if [[ -n "${{ github.event.inputs.archive_url }}" ]]; then
              # derive name from URL basename (strip query)
              URL="${{ github.event.inputs.archive_url }}"
              RAW="$(basename "${URL%%\?*}")"
            else
              # derive from uploaded file in input/
              FILE="$(ls input/* 2>/dev/null | head -n1 || true)"
              RAW="$(basename "$FILE")"
            fi
          else
            RAW="scan"
          fi
          SAN_LABEL="$(echo "${RAW}" | tr '/:@ ' '__' | tr -cd 'A-Za-z0-9._-')"
          if [[ -z "$SAN_LABEL" ]]; then SAN_LABEL="scan"; fi
          SAN_LABEL="${SAN_LABEL:0:80}"

          echo "SCAN_LABEL=$SAN_LABEL" >> "$GITHUB_ENV"
          echo "RUN_TAG=$RUN_TAG_IN"   >> "$GITHUB_ENV"
          echo "IMAGE_NAME=$SAN_LABEL" >> "$GITHUB_ENV"   # backward-compat with previous naming

      # ----------------------------------------------------
      # SCANOSS
      # ----------------------------------------------------
      - name: Run SCANOSS scan (Docker with container-scan)
        if: ${{ github.event.inputs.enable_scanoss == 'true' && github.event.inputs.scan_type == 'docker' }}
        continue-on-error: true
        run: |
          set -euo pipefail
          IMG_REF="${{ github.event.inputs.docker_image }}"
          scanoss-py container-scan "$IMG_REF" -o "scanoss_${SCAN_LABEL}.json"

      - name: Run SCANOSS scan (Auto-built image when available)
        if: |
          github.event.inputs.enable_scanoss == 'true' &&
          github.event.inputs.scan_type != 'docker' &&
          steps.autodock.outputs.has_image == 'true'
        continue-on-error: true
        run: |
          set -euo pipefail
          IMG_REF="${{ steps.autodock.outputs.image_ref }}"
          scanoss-py container-scan "$IMG_REF" -o "scanoss_${SCAN_LABEL}.json"

      - name: Run SCANOSS scan (Directory)
        if: |
          github.event.inputs.enable_scanoss == 'true' &&
          (
            (github.event.inputs.scan_type == 'git'        && steps.autodock.outputs.has_image == 'false') ||
            (github.event.inputs.scan_type == 'upload-zip' && steps.autodock.outputs.has_image == 'false') ||
            (github.event.inputs.scan_type == 'upload-tar' && steps.autodock.outputs.has_image == 'false')
          )
        continue-on-error: true
        run: |
          set -euo pipefail
          TARGET_DIR=""
          if [[ "${{ github.event.inputs.scan_type }}" == "git"        ]]; then TARGET_DIR="repo-to-scan"; fi
          if [[ "${{ github.event.inputs.scan_type }}" == "upload-zip" ]]; then TARGET_DIR="uploaded-source"; fi
          if [[ "${{ github.event.inputs.scan_type }}" == "upload-tar" ]]; then TARGET_DIR="uploaded-tar"; fi
          scanoss-py scan -d "$TARGET_DIR" -o "scanoss_${SCAN_LABEL}.json"

      # ----------------------------------------------------
      # Generate Excel from SCANOSS JSON
      # ----------------------------------------------------
      - name: Build SCANOSS Excel
        shell: bash
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import json, os, pandas as pd

          out_json = f"scanoss_{os.environ.get('SCAN_LABEL','scan')}.json"
          if not os.path.exists(out_json):
              print("No SCANOSS JSON produced; skipping Excel.")
              raise SystemExit(0)

          with open(out_json, "r", encoding="utf-8") as f:
              data = json.load(f)

          rows = []

          def add_row(file_path=None, component=None, version=None, license_=None, url=None, purl=None, vendor=None, extra=None):
              rows.append({
                  "file": file_path, "component": component, "version": version,
                  "license": license_, "url": url, "purl": purl, "vendor": vendor,
                  "extra": extra
              })

          # Try common SCANOSS shapes
          if isinstance(data, dict):
              files = data.get("files") or data.get("identified") or []
              if isinstance(files, list):
                  for f in files:
                      fpath = f.get("file") or f.get("path")
                      oss_lines = f.get("oss_lines") or f.get("oss") or []
                      if isinstance(oss_lines, list):
                          for line in oss_lines:
                              dets = line.get("oss") if isinstance(line, dict) else None
                              dets = dets if isinstance(dets, list) else [line] if isinstance(line, dict) else []
                              for d in dets:
                                  if not isinstance(d, dict): continue
                                  add_row(
                                      file_path=fpath,
                                      component=d.get("component") or d.get("name"),
                                      version=d.get("version"),
                                      license_=d.get("license") or d.get("licenses"),
                                      url=d.get("url") or d.get("homepage"),
                                      purl=d.get("purl"),
                                      vendor=d.get("vendor"),
                                      extra=json.dumps({k:v for k,v in d.items() if k not in {"component","name","version","license","licenses","url","homepage","purl","vendor"}}, ensure_ascii=False) or None
                                  )
              comps = data.get("components")
              if isinstance(comps, list):
                  for d in comps:
                      if not isinstance(d, dict): continue
                      add_row(
                          component=d.get("component") or d.get("name"),
                          version=d.get("version"),
                          license_=d.get("license") or d.get("licenses"),
                          url=d.get("url") or d.get("homepage"),
                          purl=d.get("purl"),
                          vendor=d.get("vendor"),
                          extra=json.dumps({k:v for k,v in d.items() if k not in {"component","name","version","license","licenses","url","homepage","purl","vendor"}}, ensure_ascii=False) or None
                      )
          elif isinstance(data, list):
              for f in data:
                  if not isinstance(f, dict): continue
                  fpath = f.get("file") or f.get("path")
                  dets = f.get("oss") or f.get("components") or []
                  if isinstance(dets, list):
                      for d in dets:
                          if not isinstance(d, dict): continue
                          add_row(
                              file_path=fpath,
                              component=d.get("component") or d.get("name"),
                              version=d.get("version"),
                              license_=d.get("license") or d.get("licenses"),
                              url=d.get("url") or d.get("homepage"),
                              purl=d.get("purl"),
                              vendor=d.get("vendor"),
                              extra=json.dumps({k:v for k,v in d.items() if k not in {"component","name","version","license","licenses","url","homepage","purl","vendor"}}, ensure_ascii=False) or None
                          )

          df = pd.DataFrame(rows)
          scan_label = os.environ.get("SCAN_LABEL","scan")
          xlsx_main  = f"{scan_label}_scanoss_components_report.xlsx"
          xlsx_merged= f"{scan_label}_compliance_merged_report.xlsx"    # compatibility placeholder

          if not df.empty:
              with pd.ExcelWriter(xlsx_main) as w:
                  df.to_excel(w, "SCANOSS_Components", index=False)
              with pd.ExcelWriter(xlsx_merged) as w:
                  df.to_excel(w, "Components", index=False)
              print(f"âœ… Wrote Excel: {xlsx_main} and {xlsx_merged}")
          else:
              print("âš ï¸ SCANOSS JSON parsed but produced no rows; Excel skipped.")
          PY

      # ----------------------------------------------------
      # Upload artifacts (only SCANOSS outputs)
      # ----------------------------------------------------
      - name: Upload Compliance Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: oss-scan-results-${{ env.SCAN_LABEL }}-${{ env.RUN_TAG }}
          path: |
            scanoss_${{ env.SCAN_LABEL }}.json
            ${{ env.SCAN_LABEL }}_scanoss_components_report.xlsx
            ${{ env.SCAN_LABEL }}_compliance_merged_report.xlsx
          if-no-files-found: ignore

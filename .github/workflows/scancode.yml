name: OSS Compliance - SCANOSS only (Docker, Git or Uploaded Source) with tags

run-name: >-
  SCANOSS ${{ github.event.inputs.scan_type }} •
  ${{ github.event.inputs.docker_image || github.event.inputs.git_url || github.event.inputs.archive_url || 'upload' }} •
  ${{ github.event.inputs.client_run_id }}

on:
  workflow_dispatch:
    inputs:
      scan_type:
        description: 'Scan a Docker image, Git repo, uploaded source.zip or image.tar archive'
        required: true
        default: 'docker'
        type: choice
        options: [docker, git, upload-zip, upload-tar]

      docker_image:
        description: 'Docker image name (e.g., nginx:latest) [scan_type: docker]'
        required: false

      git_url:
        description: 'Git repository URL (e.g., https://github.com/user/repo OR https://github.com/user/repo/tree/v1.2.3)'
        required: false

      git_ref:
        description: 'Branch / tag / commit to scan [scan_type: git]. Leave blank if included in git_url (tree/commit/tag).'
        required: false
        default: ''

      enable_scanoss:
        description: 'Run SCANOSS OSS scan?'
        required: false
        default: 'true'
        type: boolean

      archive_url:
        description: 'Remote .zip or .tar(.gz|.xz) URL (used only when scan_type is upload-zip or upload-tar)'
        required: false
        default: ''

      client_run_id:
        description: 'Opaque run tag from the UI (for status + artifact lookup)'
        required: false
        default: ''

jobs:
  oss-compliance:
    runs-on: ubuntu-latest
    env:
      SCANOSS_API_KEY: ${{ secrets.SCANOSS_API_KEY }}
      SCANOSS_API_URL: ${{ secrets.SCANOSS_API_URL }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install system deps
        run: |
          sudo apt-get update
          sudo apt-get install -y git curl unzip xz-utils tar

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install SCANOSS and Excel deps
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install --user scanoss pandas openpyxl
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"
          export PATH="$HOME/.local/bin:$PATH"

      # ---------- Normalize Docker image (fixes "alpine: latest") ----------
      - name: Normalize Docker image input
        if: ${{ github.event.inputs.scan_type == 'docker' }}
        shell: bash
        run: |
          set -euo pipefail
          RAW="${{ github.event.inputs.docker_image }}"
          RAW_TRIM="$(echo "$RAW" | sed -E 's/^[[:space:]]+|[[:space:]]+$//g')"
          IMG_REF="$(echo "$RAW_TRIM" | sed -E 's/[[:space:]]*:[[:space:]]*/:/g' | tr -d '\r')"
          if ! echo "$IMG_REF" | grep -Eq '^[[:alnum:]][[:alnum:]._/-]*(:[[:alnum:]._-]+)?(@sha256:[a-f0-9]{64})?$'; then
            echo "❌ Invalid docker image reference after normalization: '$IMG_REF'" >&2
            exit 1
          fi
          echo "DOCKER_IMAGE_REF=$IMG_REF" >> "$GITHUB_ENV"
          echo "✅ Using Docker image: $IMG_REF"

      # -------------------------- Prepare source --------------------------
      - name: Pull Docker image
        if: ${{ github.event.inputs.scan_type == 'docker' }}
        run: docker pull "$DOCKER_IMAGE_REF"

      - name: Clone Git repository
        if: ${{ github.event.inputs.scan_type == 'git' }}
        shell: bash
        run: |
          set -euo pipefail
          RAW_URL="${{ github.event.inputs.git_url }}"
          RAW_REF="${{ github.event.inputs.git_ref }}"
          if [[ -z "${RAW_URL}" ]]; then
            echo "❌ git_url is required when scan_type=git" >&2
            exit 1
          fi
          BASE_URL=""; DET_REF=""
          case "$RAW_URL" in
            https://github.com/*/tree/*)
              DET_REF="${RAW_URL##*/tree/}"; DET_REF="${DET_REF%%/*}"
              BASE_URL="${RAW_URL%%/tree/*}.git" ;;
            https://github.com/*/commit/*)
              DET_REF="${RAW_URL##*/commit/}"; DET_REF="${DET_REF%%/*}"
              BASE_URL="${RAW_URL%%/commit/*}.git" ;;
            https://github.com/*/releases/tag/*)
              DET_REF="${RAW_URL##*/releases/tag/}"; DET_REF="${DET_REF%%/*}"
              BASE_URL="${RAW_URL%%/releases/tag/*}.git" ;;
            https://github.com/*/*)
              BASE_URL="${RAW_URL%.git}.git" ;;
            *) BASE_URL="${RAW_URL}" ;;
          esac
          GIT_REF="${RAW_REF#refs/heads/}"; GIT_REF="${GIT_REF#refs/tags/}"
          if [[ -z "${GIT_REF}" ]]; then
            if [[ -n "${DET_REF}" ]]; then GIT_REF="${DET_REF}"; else GIT_REF="main"; fi
          fi
          echo "🔧 Repo: ${BASE_URL}"; echo "🔧 Ref:  ${GIT_REF}"
          rm -rf repo-to-scan
          if git ls-remote --tags --heads "${BASE_URL}" | grep -qE "refs/(heads|tags)/${GIT_REF}$"; then
            git clone --depth 1 --branch "${GIT_REF}" "${BASE_URL}" repo-to-scan || true
          fi
          if [[ ! -d repo-to-scan ]]; then
            git clone "${BASE_URL}" repo-to-scan
            cd repo-to-scan
            git fetch --all --tags --prune
            git checkout --detach "${GIT_REF}" || { echo "❌ Ref not found"; exit 1; }
            cd -
          fi
          echo "✔ Checked out $(cd repo-to-scan && git rev-parse --short HEAD)"

      - name: Unzip uploaded source archive (or download ZIP)
        if: ${{ github.event.inputs.scan_type == 'upload-zip' }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p uploaded-source
          URL="${{ github.event.inputs.archive_url }}"
          if [[ -n "$URL" ]]; then
            echo "📥 Downloading ZIP from $URL …"
            curl -L --fail --retry 3 --retry-delay 2 "$URL" -o input.zip
            unzip -q input.zip -d uploaded-source
          else
            unzip -q input/*.zip -d uploaded-source
          fi

      - name: Extract uploaded TAR archive (or download TAR)
        if: ${{ github.event.inputs.scan_type == 'upload-tar' }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p uploaded-tar
          URL="${{ github.event.inputs.archive_url }}"
          if [[ -n "$URL" ]]; then
            echo "📥 Downloading TAR from $URL …"
            curl -L --fail --retry 3 --retry-delay 2 "$URL" -o input.tar
            SRC="input.tar"
          else
            SRC=$(ls input/*.tar 2>/dev/null | head -n1 || true)
            if [[ -z "$SRC" ]]; then
              echo "❌ No TAR found in input/ and no archive_url provided." >&2
              exit 1
            fi
          fi
          NAME="${SRC##*/}"
          case "$NAME" in
            *.tar.gz|*.tgz)  tar -xzf "$SRC" -C uploaded-tar ;;
            *.tar.xz|*.txz)  tar -xJf "$SRC" -C uploaded-tar ;;
            *.tar)           tar -xf  "$SRC" -C uploaded-tar ;;
            *)               echo "ℹ️ Unknown TAR extension; trying generic -xf"; tar -xf "$SRC" -C uploaded-tar ;;
          esac

      # ---- Auto-detect Dockerfile & optionally build an image (non-docker modes) ----
      - name: Detect Dockerfile and optionally build image
        id: autodock
        if: ${{ github.event.inputs.scan_type != 'docker' }}
        run: |
          set -e
          SCAN_DIR="."
          if [[ "${{ github.event.inputs.scan_type }}" == "git"        ]]; then SCAN_DIR="repo-to-scan"; fi
          if [[ "${{ github.event.inputs.scan_type }}" == "upload-zip" ]]; then SCAN_DIR="uploaded-source"; fi
          if [[ "${{ github.event.inputs.scan_type }}" == "upload-tar" ]]; then SCAN_DIR="uploaded-tar"; fi
          HAS_IMAGE=false; IMAGE_REF=""
          DF_PATH=$(find "$SCAN_DIR" -type f -iname 'Dockerfile' | head -n 1 || true)
          if [[ -n "$DF_PATH" ]]; then
            if docker build -t auto-scanned-image:latest "$(dirname "$DF_PATH")"; then
              HAS_IMAGE=true; IMAGE_REF="auto-scanned-image:latest"
              echo "✅ Docker image built"
            else
              echo "⚠️ Docker build failed – skipping image-based scan"
            fi
          else
            echo "No Dockerfile – skip image build"
          fi
          echo "has_image=$HAS_IMAGE"  >> "$GITHUB_OUTPUT"
          echo "image_ref=$IMAGE_REF"  >> "$GITHUB_OUTPUT"

      # --------------- Label + run tag for artifact names ---------------
      - name: Set LABEL and RUN_TAG env
        shell: bash
        run: |
          set -euo pipefail
      
          # ---- RUN_TAG: take client_run_id or fallback to GITHUB_RUN_ID, then SANITIZE ----
          RUN_TAG_IN="${{ github.event.inputs.client_run_id }}"
          if [ -z "${RUN_TAG_IN}" ]; then RUN_TAG_IN="${GITHUB_RUN_ID}"; fi
      
          # Replace disallowed chars with '_' and keep only [A-Za-z0-9._-], max 80 chars
          SAN_RUN_TAG="$(echo "$RUN_TAG_IN" | tr '/:@\"<>|*?\r\n\\ ' '_' | tr -cd 'A-Za-z0-9._-')"
          if [ -z "$SAN_RUN_TAG" ]; then SAN_RUN_TAG="${GITHUB_RUN_ID}"; fi
          SAN_RUN_TAG="${SAN_RUN_TAG:0:80}"
      
          # ---- SCAN_LABEL: compute from source and sanitize (unchanged logic) ----
          MODE="${{ github.event.inputs.scan_type }}"
          RAW=""
          if [[ "$MODE" == "docker" ]]; then
            RAW="${DOCKER_IMAGE_REF:-${{ github.event.inputs.docker_image }}}"
          elif [[ "$MODE" == "git" ]]; then
            RAW="${{ github.event.inputs.git_url }}"
          elif [[ "$MODE" == "upload-zip" || "$MODE" == "upload-tar" ]]; then
            if [[ -n "${{ github.event.inputs.archive_url }}" ]]; then
              URL="${{ github.event.inputs.archive_url }}"; RAW="$(basename "${URL%%\?*}")"
            else
              FILE="$(ls input/* 2>/dev/null | head -n1 || true)"; RAW="$(basename "$FILE")"
            fi
            if [[ -z "$RAW" ]]; then RAW="$MODE"; fi
          else
            RAW="scan"
          fi
          SAN_LABEL="$(echo "${RAW}" | tr '/:@\"<>|*?\r\n\\ ' '_' | tr -cd 'A-Za-z0-9._-')"
          if [[ -z "$SAN_LABEL" ]]; then SAN_LABEL="scan"; fi
          SAN_LABEL="${SAN_LABEL:0:80}"
      
          echo "SCAN_LABEL=$SAN_LABEL" >> "$GITHUB_ENV"
          echo "RUN_TAG=$SAN_RUN_TAG"  >> "$GITHUB_ENV"
          echo "IMAGE_NAME=$SAN_LABEL" >> "$GITHUB_ENV"
      
          echo "🧾 Artifact base: oss-scan-results-${SAN_LABEL}-${SAN_RUN_TAG}"


      # -------------------- SCANOSS (no Syft anywhere) --------------------
      - name: Run SCANOSS scan (Docker, no Syft)
        if: ${{ github.event.inputs.enable_scanoss == 'true' && github.event.inputs.scan_type == 'docker' }}
        continue-on-error: true
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p docker-output/extracted-rootfs
          docker save "$DOCKER_IMAGE_REF" -o docker-output/image.tar
          tar -xf docker-output/image.tar -C docker-output
          find docker-output -name 'layer.tar' -print0 | xargs -0 -I{} tar -xf {} -C docker-output/extracted-rootfs
          scanoss-py scan -d docker-output/extracted-rootfs -o "scanoss_${SCAN_LABEL}.json"

      - name: Run SCANOSS scan (Auto-built image, no Syft)
        if: |
          github.event.inputs.enable_scanoss == 'true' &&
          github.event.inputs.scan_type != 'docker' &&
          steps.autodock.outputs.has_image == 'true'
        continue-on-error: true
        shell: bash
        run: |
          set -euo pipefail
          IMG_REF="${{ steps.autodock.outputs.image_ref }}"
          mkdir -p docker-output/extracted-rootfs
          docker save "$IMG_REF" -o docker-output/image.tar
          tar -xf docker-output/image.tar -C docker-output
          find docker-output -name 'layer.tar' -print0 | xargs -0 -I{} tar -xf {} -C docker-output/extracted-rootfs
          scanoss-py scan -d docker-output/extracted-rootfs -o "scanoss_${SCAN_LABEL}.json"

      - name: Run SCANOSS scan (Directory)
        if: |
          github.event.inputs.enable_scanoss == 'true' &&
          (
            (github.event.inputs.scan_type == 'git'        && steps.autodock.outputs.has_image == 'false') ||
            (github.event.inputs.scan_type == 'upload-zip' && steps.autodock.outputs.has_image == 'false') ||
            (github.event.inputs.scan_type == 'upload-tar' && steps.autodock.outputs.has_image == 'false')
          )
        continue-on-error: true
        shell: bash
        run: |
          set -euo pipefail
          TARGET_DIR=""
          if [[ "${{ github.event.inputs.scan_type }}" == "git"        ]]; then TARGET_DIR="repo-to-scan"; fi
          if [[ "${{ github.event.inputs.scan_type }}" == "upload-zip" ]]; then TARGET_DIR="uploaded-source"; fi
          if [[ "${{ github.event.inputs.scan_type }}" == "upload-tar" ]]; then TARGET_DIR="uploaded-tar"; fi
          scanoss-py scan -d "$TARGET_DIR" -o "scanoss_${SCAN_LABEL}.json"

      # ----------------------- Debug SCANOSS JSON ------------------------
      - name: Inspect SCANOSS JSON (debug)
        shell: bash
        run: |
          set -euo pipefail
          F="scanoss_${SCAN_LABEL}.json"
          if [[ -f "$F" ]]; then
            echo "File: $F"
            echo "Size: $(wc -c < "$F") bytes"
            echo "Preview:"
            head -c 2000 "$F" | sed 's/[^[:print:]\t]/?/g'
          else
            echo "JSON not found."
          fi

      # ---------------- SCANOSS JSON ➜ Excel (always write) --------------
      - name: Build SCANOSS Excel
        shell: bash
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import json, os, pandas as pd
          scan_label = os.environ.get("SCAN_LABEL","scan")
          out_json = f"scanoss_{scan_label}.json"
          xlsx_main  = f"{scan_label}_scanoss_components_report.xlsx"
          xlsx_merged= f"{scan_label}_compliance_merged_report.xlsx"
          rows = []
          if os.path.exists(out_json):
              try:
                  with open(out_json, "r", encoding="utf-8") as f:
                      data = json.load(f)
              except Exception as e:
                  data = None
              def add_row(file_path=None, component=None, version=None, license_=None, url=None, purl=None, vendor=None, extra=None):
                  rows.append({
                      "file": file_path, "component": component, "version": version,
                      "license": license_, "url": url, "purl": purl, "vendor": vendor, "extra": extra
                  })
              if isinstance(data, dict):
                  files = data.get("files") or data.get("identified") or []
                  if isinstance(files, list):
                      for f in files:
                          fpath = f.get("file") or f.get("path")
                          oss_lines = f.get("oss_lines") or f.get("oss") or []
                          if isinstance(oss_lines, list):
                              for line in oss_lines:
                                  dets = line.get("oss") if isinstance(line, dict) else None
                                  dets = dets if isinstance(dets, list) else ([line] if isinstance(line, dict) else [])
                                  for d in dets or []:
                                      if not isinstance(d, dict): continue
                                      keep = {k:v for k,v in d.items() if k not in {"component","name","version","license","licenses","url","homepage","purl","vendor"}}
                                      add_row(fpath, d.get("component") or d.get("name"), d.get("version"),
                                              d.get("license") or d.get("licenses"),
                                              d.get("url") or d.get("homepage"), d.get("purl"), d.get("vendor"),
                                              json.dumps(keep, ensure_ascii=False) or None)
                  comps = data.get("components")
                  if isinstance(comps, list):
                      for d in comps:
                          if not isinstance(d, dict): continue
                          keep = {k:v for k,v in d.items() if k not in {"component","name","version","license","licenses","url","homepage","purl","vendor"}}
                          add_row(None, d.get("component") or d.get("name"), d.get("version"),
                                  d.get("license") or d.get("licenses"),
                                  d.get("url") or d.get("homepage"), d.get("purl"), d.get("vendor"),
                                  json.dumps(keep, ensure_ascii=False) or None)
              elif isinstance(data, list):
                  for f in data:
                      if not isinstance(f, dict): continue
                      fpath = f.get("file") or f.get("path")
                      dets = f.get("oss") or f.get("components") or []
                      if isinstance(dets, list):
                          for d in dets:
                              if not isinstance(d, dict): continue
                              keep = {k:v for k,v in d.items() if k not in {"component","name","version","license","licenses","url","homepage","purl","vendor"}}
                              add_row(fpath, d.get("component") or d.get("name"), d.get("version"),
                                      d.get("license") or d.get("licenses"),
                                      d.get("url") or d.get("homepage"), d.get("purl"), d.get("vendor"),
                                      json.dumps(keep, ensure_ascii=False) or None)
          # Always write an Excel (even if no rows)
          df = pd.DataFrame(rows)
          with pd.ExcelWriter(xlsx_main) as w:
              if not df.empty:
                  df.to_excel(w, "SCANOSS_Components", index=False)
              else:
                  pd.DataFrame([{"status":"No detections","hint":"Try a larger repo/image or ensure SCANOSS_API_KEY is set if your tenant requires it."}]).to_excel(w, "Summary", index=False)
          with pd.ExcelWriter(xlsx_merged) as w:
              (df if not df.empty else pd.DataFrame([{"status":"No detections"}])).to_excel(w, "Components", index=False)
          print(f"✅ Wrote Excel: {xlsx_main} and {xlsx_merged} (rows={len(df)})")
          PY

      - name: Upload Compliance Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: oss-scan-results-${{ env.SCAN_LABEL }}-${{ env.RUN_TAG }}
          path: |
            scanoss_${{ env.SCAN_LABEL }}.json
            ${{ env.SCAN_LABEL }}_scanoss_components_report.xlsx
            ${{ env.SCAN_LABEL }}_compliance_merged_report.xlsx
          if-no-files-found: ignore
